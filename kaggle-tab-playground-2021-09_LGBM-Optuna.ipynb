{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular Playground September 2021\r\n",
    "\r\n",
    "This notebook handles model tuning for the logistic regression model developed for the Kaggle Tabular Playground September 2021 Competition.  For EDA, FE, and initial model development, see the previous notebooks [here](https://github.com/mcnewcp/kaggle-tabular-playground-series-sep21/blob/coy/kaggle-tab-playground-2021-09_MI-PCA.ipynb) and [here](https://github.com/mcnewcp/kaggle-tabular-playground-series-sep21/blob/coy/kaggle-tab-playground-2021-09_FE%2BLogReg-RF-XGB.ipynb).\r\n",
    "\r\n",
    "# Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "test = pd.read_csv('datasets/test.csv')\r\n",
    "train = pd.read_csv('datasets/train.csv')\r\n",
    "\r\n",
    "# ######TEMP REDUCE DATA SIZE\r\n",
    "# train = train.sample(1000)\r\n",
    "\r\n",
    "X_train = train.drop(['id', 'claim'], axis=1)\r\n",
    "y_train = train.claim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Pipeline\r\n",
    "\r\n",
    "## Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from scipy import stats\r\n",
    "\r\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\r\n",
    "    #one hyperparameter per new feature\r\n",
    "    def __init__(\r\n",
    "        self, \r\n",
    "        add_sum = True, \r\n",
    "        add_num_nan = True,\r\n",
    "        add_abs_sum = True, \r\n",
    "        add_sem = True\r\n",
    "    ): #no *args or **kargs\r\n",
    "        self.add_sum = add_sum\r\n",
    "        self.add_num_nan = add_num_nan\r\n",
    "        self.add_abs_sum = add_abs_sum\r\n",
    "        self.add_sem = add_sem\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        return self #nothing to fit\r\n",
    "    def transform(self, X):\r\n",
    "        #generate additional features\r\n",
    "        if self.add_sum:\r\n",
    "            std_scaler = StandardScaler()\r\n",
    "            sum_col = X.copy()\r\n",
    "            sum_col[np.isnan(sum_col)] = 0\r\n",
    "            sum_col = std_scaler.fit_transform(sum_col)\r\n",
    "            sum_col = sum_col.sum(axis=1)\r\n",
    "            X = np.c_[X, sum_col]\r\n",
    "        if self.add_num_nan:\r\n",
    "            num_nan = np.isnan(X).sum(axis=1)\r\n",
    "            X = np.c_[X, num_nan]\r\n",
    "        if self.add_abs_sum:\r\n",
    "            abs_sum = X.copy()\r\n",
    "            abs_sum[np.isnan(abs_sum)] = 0\r\n",
    "            abs_sum = np.abs(abs_sum).sum(axis=1)\r\n",
    "            X = np.c_[X, abs_sum]\r\n",
    "        if self.add_sem:\r\n",
    "            sem_col = stats.sem(X, nan_policy = 'omit', axis=1)\r\n",
    "            X = np.c_[X, sem_col]\r\n",
    "        return X\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler = StandardScaler()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from lightgbm import LGBMClassifier\r\n",
    "\r\n",
    "model = Pipeline([\r\n",
    "    ('attr_adder', CombinedAttributesAdder()),\r\n",
    "    ('imputer', SimpleImputer()),\r\n",
    "    ('std_scaler', scaler),\r\n",
    "    ('lgbm', LGBMClassifier(silent=False, objective='binary'))\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tuning\r\n",
    "\r\n",
    "For tuning I'm going to use the `Optuna` package.  Optuna provides a number of really cool features when it comes to tuning hyperparameters and processing steps, including built in plotly diagnostic plots.  A pretty good intro to Optuna can be found [here](https://towardsdatascience.com/how-to-make-your-model-awesome-with-optuna-b56d490368af). \r\n",
    "\r\n",
    "The package works by minimizing an objective function.  The objective function must be defined so that it returns a single value which is the score minimized by the optuna study.  It is suggested to use cv score when scoring inside the objective function.  All possible hyperparameters must be chosen using the built in `trial.suggest_**` functions.  5 possible distributions options are provided:\r\n",
    "\r\n",
    "* uniform — float values\r\n",
    "* log-uniform — float values\r\n",
    "* discrete uniform — float values with intervals\r\n",
    "* integer — integer values\r\n",
    "* categorical — categorical values from a list\r\n",
    "\r\n",
    "Of course you can access any hyperparameters along the pipeline using the `step__hyperparam` nomenclature.  I'm also including a pickling step in the objective below, so that I can load intermediate results in case the process is interrupted or if I want to add onto the study."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import optuna\r\n",
    "import joblib\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.model_selection import cross_val_predict\r\n",
    "\r\n",
    "def objective(trial):\r\n",
    "\r\n",
    "    joblib.dump(study, 'study-lgbm.pkl')\r\n",
    "\r\n",
    "    attr_adder__add_sum = trial.suggest_categorical('attr_adder__add_sum', [False, True])\r\n",
    "    attr_adder__add_num_nan = trial.suggest_categorical('attr_adder__add_num_nan', [False, True])\r\n",
    "    attr_adder__add_abs_sum = trial.suggest_categorical('attr_adder__add_abs_sum', [False, True])\r\n",
    "    attr_adder__add_sem = trial.suggest_categorical('attr_adder__add_sem', [False, True])\r\n",
    "    imputer__strategy = trial.suggest_categorical('imputer__strategy', ['median', 'mean', 'constant', 'most_frequent'])\r\n",
    "    lgbm__boosting_type = trial.suggest_categorical('lgbm__boosting_type', ['gbdt', 'goss'])\r\n",
    "    lgbm__num_leaves = trial.suggest_int('lgbm__num_leaves', 2, 200)\r\n",
    "    lgbm__max_depth = trial.suggest_int('lgbm__max_depth', -1, 50)\r\n",
    "    lgbm__learning_rate = trial.suggest_uniform('lgbm__learning_rate', 0.01, 1)\r\n",
    "    lgbm__n_estimators = trial.suggest_int('lgbm__n_estimators', 10, 500)\r\n",
    "    lgbm__reg_alpha = trial.suggest_loguniform('lgbm__reg_alpha', 0.1, 100)\r\n",
    "    lgbm__reg_lambda = trial.suggest_loguniform('lgbm__reg_lambda', 0.1, 100)\r\n",
    "\r\n",
    "\r\n",
    "    params = {\r\n",
    "        'attr_adder__add_sum': attr_adder__add_sum,\r\n",
    "        'attr_adder__add_num_nan': attr_adder__add_num_nan,\r\n",
    "        'attr_adder__add_abs_sum': attr_adder__add_abs_sum, \r\n",
    "        'attr_adder__add_sem': attr_adder__add_sem, \r\n",
    "        'imputer__strategy': imputer__strategy,\r\n",
    "        'lgbm__boosting_type': lgbm__boosting_type,\r\n",
    "        'lgbm__num_leaves': lgbm__num_leaves,\r\n",
    "        'lgbm__max_depth': lgbm__max_depth,\r\n",
    "        'lgbm__learning_rate': lgbm__learning_rate, \r\n",
    "        'lgbm__n_estimators': lgbm__n_estimators, \r\n",
    "        'lgbm__reg_alpha': lgbm__reg_alpha, \r\n",
    "        'lgbm__reg_lambda': lgbm__reg_lambda\r\n",
    "    }\r\n",
    "\r\n",
    "    model.set_params(**params)\r\n",
    "\r\n",
    "    preds = cross_val_predict(\r\n",
    "        model, X_train, y_train, cv=3, method=\"predict_proba\", n_jobs = -1\r\n",
    "    )\r\n",
    "    preds = preds[:,1].reshape(len(preds))\r\n",
    "    \r\n",
    "    return roc_auc_score(y_train, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now all that's left to do is create the study (or load a previously pickled version) and optimize the objective.  You can specify how long the study lasts in number of trials (`n_trials`) or in time in seconds (`timeout`).  Setting `timeout` defines the time which the last trial must start before, and therefore the study last longer than the `timeout`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "study = optuna.create_study(direction='maximize')\r\n",
    "study.optimize(objective, timeout=14400)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-09-30 08:56:23,904]\u001b[0m A new study created in memory with name: no-name-d016f059-c329-48d3-8d20-21533b27e2b7\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 08:58:04,342]\u001b[0m Trial 0 finished with value: 0.7273652578377864 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': False, 'attr_adder__add_abs_sum': False, 'attr_adder__add_sem': False, 'imputer__strategy': 'constant', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 65, 'lgbm__max_depth': 11, 'lgbm__learning_rate': 0.9121321441710888, 'lgbm__n_estimators': 322, 'lgbm__reg_alpha': 0.1815735081606458, 'lgbm__reg_lambda': 5.8716749010312395}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:01:12,502]\u001b[0m Trial 1 finished with value: 0.7115646215989976 and parameters: {'attr_adder__add_sum': True, 'attr_adder__add_num_nan': False, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': False, 'imputer__strategy': 'mean', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 124, 'lgbm__max_depth': 10, 'lgbm__learning_rate': 0.683916228134584, 'lgbm__n_estimators': 357, 'lgbm__reg_alpha': 1.9537234458764285, 'lgbm__reg_lambda': 3.8075386124228094}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:01:41,353]\u001b[0m Trial 2 finished with value: 0.5477654591906749 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': False, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': False, 'imputer__strategy': 'mean', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 7, 'lgbm__max_depth': 1, 'lgbm__learning_rate': 0.07689160982728449, 'lgbm__n_estimators': 57, 'lgbm__reg_alpha': 1.2727213304303886, 'lgbm__reg_lambda': 23.492209511464058}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:03:16,127]\u001b[0m Trial 3 finished with value: 0.7067300783997695 and parameters: {'attr_adder__add_sum': True, 'attr_adder__add_num_nan': False, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': True, 'imputer__strategy': 'constant', 'lgbm__boosting_type': 'goss', 'lgbm__num_leaves': 187, 'lgbm__max_depth': 25, 'lgbm__learning_rate': 0.37075250752511024, 'lgbm__n_estimators': 129, 'lgbm__reg_alpha': 17.5185037230352, 'lgbm__reg_lambda': 1.3916839105234884}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:04:37,519]\u001b[0m Trial 4 finished with value: 0.7212061013222312 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': False, 'imputer__strategy': 'most_frequent', 'lgbm__boosting_type': 'goss', 'lgbm__num_leaves': 32, 'lgbm__max_depth': 42, 'lgbm__learning_rate': 0.46398880151685884, 'lgbm__n_estimators': 464, 'lgbm__reg_alpha': 0.12261627933419879, 'lgbm__reg_lambda': 1.9441526462306393}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:05:47,529]\u001b[0m Trial 5 finished with value: 0.7122690578707634 and parameters: {'attr_adder__add_sum': True, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': True, 'imputer__strategy': 'median', 'lgbm__boosting_type': 'goss', 'lgbm__num_leaves': 119, 'lgbm__max_depth': 22, 'lgbm__learning_rate': 0.7558665172890955, 'lgbm__n_estimators': 96, 'lgbm__reg_alpha': 0.344524480270773, 'lgbm__reg_lambda': 0.3051992221102038}. Best is trial 0 with value: 0.7273652578377864.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:07:36,244]\u001b[0m Trial 6 finished with value: 0.8131927616907066 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': True, 'imputer__strategy': 'median', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 13, 'lgbm__max_depth': 6, 'lgbm__learning_rate': 0.33128352788314464, 'lgbm__n_estimators': 326, 'lgbm__reg_alpha': 66.02324001768241, 'lgbm__reg_lambda': 12.641556069084036}. Best is trial 6 with value: 0.8131927616907066.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:09:11,866]\u001b[0m Trial 7 finished with value: 0.7968727061157529 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': False, 'attr_adder__add_sem': False, 'imputer__strategy': 'most_frequent', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 142, 'lgbm__max_depth': 8, 'lgbm__learning_rate': 0.9981079026506122, 'lgbm__n_estimators': 149, 'lgbm__reg_alpha': 68.09475763507707, 'lgbm__reg_lambda': 89.1630321696777}. Best is trial 6 with value: 0.8131927616907066.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:10:49,067]\u001b[0m Trial 8 finished with value: 0.810697359147622 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': False, 'attr_adder__add_sem': True, 'imputer__strategy': 'median', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 5, 'lgbm__max_depth': 11, 'lgbm__learning_rate': 0.657805634231917, 'lgbm__n_estimators': 438, 'lgbm__reg_alpha': 1.1830711036763804, 'lgbm__reg_lambda': 14.947391782402308}. Best is trial 6 with value: 0.8131927616907066.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:14:08,680]\u001b[0m Trial 9 finished with value: 0.7371151797402454 and parameters: {'attr_adder__add_sum': False, 'attr_adder__add_num_nan': False, 'attr_adder__add_abs_sum': False, 'attr_adder__add_sem': False, 'imputer__strategy': 'most_frequent', 'lgbm__boosting_type': 'gbdt', 'lgbm__num_leaves': 135, 'lgbm__max_depth': 7, 'lgbm__learning_rate': 0.7707961217513427, 'lgbm__n_estimators': 420, 'lgbm__reg_alpha': 51.268297458551736, 'lgbm__reg_lambda': 0.5143823393573497}. Best is trial 6 with value: 0.8131927616907066.\u001b[0m\n",
      "\u001b[32m[I 2021-09-30 09:15:49,789]\u001b[0m Trial 10 finished with value: 0.7845669724897871 and parameters: {'attr_adder__add_sum': True, 'attr_adder__add_num_nan': True, 'attr_adder__add_abs_sum': True, 'attr_adder__add_sem': True, 'imputer__strategy': 'median', 'lgbm__boosting_type': 'goss', 'lgbm__num_leaves': 74, 'lgbm__max_depth': 26, 'lgbm__learning_rate': 0.21685841892986463, 'lgbm__n_estimators': 247, 'lgbm__reg_alpha': 13.207792965456203, 'lgbm__reg_lambda': 0.11128994152407666}. Best is trial 6 with value: 0.8131927616907066.\u001b[0m\n",
      "\u001b[33m[W 2021-09-30 09:16:15,944]\u001b[0m Trial 11 failed because of the following error: LightGBMError('Check failed: (num_leaves) > (1) at D:\\\\a\\\\1\\\\s\\\\python-package\\\\compile\\\\src\\\\io\\\\config_auto.cpp, line 324 .\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-5-5c347cee8746>\", line 41, in objective\n",
      "    preds = cross_val_predict(\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in cross_val_predict\n",
      "    predictions = parallel(delayed(_fit_and_predict)(\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py\", line 1054, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py\", line 933, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\concurrent\\futures\\_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Python\\Miniconda\\envs\\test-env\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "lightgbm.basic.LightGBMError: Check failed: (num_leaves) > (1) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 324 .\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "LightGBMError",
     "evalue": "Check failed: (num_leaves) > (1) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 324 .\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0cc225d28fa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5c347cee8746>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     preds = cross_val_predict(\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"predict_proba\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     )\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    864\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    865\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 866\u001b[1;33m     predictions = parallel(delayed(_fit_and_predict)(\n\u001b[0m\u001b[0;32m    867\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m    868\u001b[0m         for train, test in splits)\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda\\envs\\test-env\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Check failed: (num_leaves) > (1) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 324 .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Results\r\n",
    "\r\n",
    "Optuna provides some really interesting visuals baked right into the study object.  Most are built with plotly, meaning you get a little interactivity to play with.\r\n",
    "\r\n",
    "## Hyperparameter Importance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import plotly\r\n",
    "optuna.visualization.plot_param_importances(study)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimization History"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Slices\r\n",
    "\r\n",
    "The slice plots give you an idea of the affect of each hyperparameter individually on the outcome of the objective."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optuna.visualization.plot_slice(study)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or you can look at hyperparameters individually."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optuna.visualization.plot_slice(study, ['lgbm__learning_rate'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\r\n",
    "\r\n",
    "Now to predict the test set with the final model and submit predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_mod = model.set_params(**study.best_params)\r\n",
    "final_mod.fit(X_train, y_train)\r\n",
    "\r\n",
    "# Preprocessing of test data, get predictions\r\n",
    "X_test_ids = test.id\r\n",
    "X_test = test.drop('id', axis=1)\r\n",
    "preds = final_mod.predict_proba(X_test)\r\n",
    "preds = preds[:,1].reshape(len(preds))\r\n",
    "\r\n",
    "#export predictions\r\n",
    "output = pd.DataFrame({'id': X_test_ids,\r\n",
    "                       'claim': preds})\r\n",
    "output.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('test-env': conda)"
  },
  "interpreter": {
   "hash": "217afb6d47e1ecfe9bc2bb1d008138758dfc335ae7a13eb273c90375d6240835"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}